<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="A python function to pull data from Nasdaq Data Link using the tables API and then complete the data for ease of use."><title>Nasdaq Data Link Tables API Data Retrieval</title><link rel=canonical href=https://www.jaredszajkowski.com/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/><link rel=stylesheet href=/scss/style.min.ab654ead0c454176ba44ec329bf62a4d1b745135669635bcec871ef38e2b753b.css><meta property='og:title' content="Nasdaq Data Link Tables API Data Retrieval"><meta property='og:description' content="A python function to pull data from Nasdaq Data Link using the tables API and then complete the data for ease of use."><meta property='og:url' content='https://www.jaredszajkowski.com/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/'><meta property='og:site_name' content='Jared Szajkowski, P.E., PMP'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2023-12-24T00:00:01+00:00'><meta property='article:modified_time' content='2023-12-26T00:00:00+00:00'><meta property='og:image' content='https://www.jaredszajkowski.com/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/cover.jpg'><meta name=twitter:title content="Nasdaq Data Link Tables API Data Retrieval"><meta name=twitter:description content="A python function to pull data from Nasdaq Data Link using the tables API and then complete the data for ease of use."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://www.jaredszajkowski.com/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/cover.jpg'><link rel="shortcut icon" href=/profile_pic.jpg></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/profile_pic_hu_881607cd4e70319a.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Jared Szajkowski, P.E., PMP</a></h1><h2 class=site-description></h2></div></header><ol class=menu-social><li><a href=mailto:jared.szajkowski@gmail.com target=_blank title=Email rel=me><svg class="icon icon-tabler icon-tabler-mail" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 7a2 2 0 012-2h14a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2V7z"/><path d="M3 7l9 6 9-6"/></svg></a></li><li><a href=https://github.com/jaredszajkowski target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://www.linkedin.com/in/jaredszajkowski/ target=_blank title=LinkedIn rel=me><svg class="icon icon-tabler icon-tabler-brand-linkedin" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 012-2h12a2 2 0 012 2v12a2 2 0 01-2 2H6a2 2 0 01-2-2z"/><path d="M8 11v5"/><path d="M8 8v.01"/><path d="M12 16v-5"/><path d="M16 16v-3a2 2 0 00-4 0"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/about-me/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About Me</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#introduction>Introduction</a></li><li><a href=#nasdaq-data-link-initial-data-retrieval>Nasdaq Data Link Initial Data Retrieval</a></li><li><a href=#data-questions>Data questions</a></li><li><a href=#assumptions>Assumptions</a></li><li><a href=#python-function-to-modify-the-data>Python function to modify the data</a></li><li><a href=#imports>Imports</a></li><li><a href=#ndl-api-key>NDL API Key</a></li><li><a href=#download-data-as-a-dataframe>Download data as a dataframe</a></li><li><a href=#sort-columns-by-date>Sort columns by date</a></li><li><a href=#setting-the-date-as-the-index>Setting the date as the index</a></li><li><a href=#calculating-splits>Calculating splits</a></li><li><a href=#combining-dataframes>Combining dataframes</a></li><li><a href=#forward-filling-cumulative-split-values>Forward filling cumulative split values</a></li><li><a href=#calculating-adjusted-and-non-adjusted-prices>Calculating adjusted and non-adjusted prices</a></li><li><a href=#export-data>Export data</a></li><li><a href=#output-confirmation>Output confirmation</a></li><li><a href=#references>References</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/cover.jpg width=1920 height=800 loading=lazy alt="Featured image of post Nasdaq Data Link Tables API Data Retrieval"></a></div><div class=article-details><header class=article-category><a href=/categories/nasdaq-data-link/ style=background-color:#009ad7;color:>Nasdaq Data Link
</a><a href=/categories/pandas/ style=background-color:#130754;color:>Pandas
</a><a href=/categories/python/ style=background-color:#306998;color:>Python</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/>Nasdaq Data Link Tables API Data Retrieval</a></h2><h3 class=article-subtitle>A python function to pull data from Nasdaq Data Link using the tables API and then complete the data for ease of use.</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2023-12-24T00:00:01Z>December 24, 2023</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>10 minute read</time></div></footer></div></header><section class=article-content><h2 id=introduction>Introduction</h2><p>In this tutorial, we will write a python function that pulls data from Nasdaq Data Link through the tables API, adds relevant columns that are not present in the raw data, updates columns to allow for ease of use, and leaves the data in a format where it can then be used in time series analysis.</p><p><a class=link href=https://www.nasdaq.com/nasdaq-data-link target=_blank rel=noopener>Nasdaq Data Link</a> is a provider of numerous different types of financial data from many different asset classes. It provides API&rsquo;s that allow access from Python, R, Excel, and other methods. It is available to <a class=link href=https://data.nasdaq.com/institutional-investors target=_blank rel=noopener>institutional investors</a> as well as <a class=link href=https://data.nasdaq.com/individual-users target=_blank rel=noopener>individual retail investors</a>.</p><h2 id=nasdaq-data-link-initial-data-retrieval>Nasdaq Data Link Initial Data Retrieval</h2><p>We will use the data for AAPL for this example. This will give us a data set that requires some thought as to how the splits need to be handled as well as the dividends.</p><p>We&rsquo;ll start with pulling the initial data set, with the first 10 rows shown as follows from the pandas dataframe:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/01_AAPL_data_first_10_rows.png width=1067 height=320 loading=lazy alt="AAPL Data - First 10 Rows" class=gallery-image data-flex-grow=333 data-flex-basis=800px></p><p>And the last 10 rows:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/02_AAPL_data_last_10_rows.png width=1038 height=317 loading=lazy alt="AAPL Data - Last 10 Rows" class=gallery-image data-flex-grow=327 data-flex-basis=785px></p><p>From left to right, we have the following columns:</p><ol><li>Row number: 0 indexed, gives us the total number of rows/dates of data</li><li>Ticker: The ticker symbol for our data</li><li>Date: In the format YYYY-MM-DD</li><li>Open: Daily open</li><li>High: Daily high</li><li>Low: Daily low</li><li>Close: Daily close</li><li>Volume: Volume of shares traded</li><li>Dividend: Dividend paid on that date</li><li>Split: Split executed on that date</li><li>Adjusted Open: Daily open price adusted for all splits and dividends</li><li>Adjusted High: Daily high price adusted for all splits and dividends</li><li>Adjusted Low: Daily low price adusted for all splits and dividends</li><li>Adjusted Close: Daily close price adusted for all splits and dividends</li><li>Adjusted Volume: Daily volume price adusted for all splits</li></ol><h2 id=data-questions>Data questions</h2><p>The above information is a good starting point, but what if we are looking for the following answers?</p><ol><li>The data shows a split value for every day, but we know the stock didn&rsquo;t split every day. What does this represent?</li><li>What is the total cumulative split ratio?</li><li>What is the split ratio at different points in time?</li><li>What is the adjusted share price without including the dividends? This would be needed for any time series analysis.</li><li>What is the dividend dollar value based on an adjusted share price?</li><li>What would the share price be if the stock hadn&rsquo;t split?</li></ol><p>We&rsquo;ll add columns and modify as necessary to answer the above questions and more.</p><h2 id=assumptions>Assumptions</h2><p>The remainder of this tutorial assumes the following:</p><ul><li>You have the <a class=link href=https://github.com/Nasdaq/data-link-python target=_blank rel=noopener>Nasdaq Data Link</a> library installed</li><li>You have the <a class=link href=https://pandas.pydata.org/ target=_blank rel=noopener>pandas</a> library installed</li><li>You have the <a class=link href=https://openpyxl.readthedocs.io/en/stable/ target=_blank rel=noopener>OpenPyXL</a> library installed</li></ul><h2 id=python-function-to-modify-the-data>Python function to modify the data</h2><p>The following function will perform the desired modifications:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># This function pulls the data for the specific fund from from Nasdaq Data</span>
</span></span><span class=line><span class=cl><span class=c1># Link and adds many missing columns</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Imports</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nasdaqdatalink</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Add API key for reference to allow access to unrestricted data</span>
</span></span><span class=line><span class=cl><span class=n>nasdaqdatalink</span><span class=o>.</span><span class=n>ApiConfig</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=s1>&#39;your_key&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Function definition</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>ndl_data_updater</span><span class=p>(</span><span class=n>fund</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Command to pull data</span>
</span></span><span class=line><span class=cl>    <span class=c1># If start date and end date are not specified the entire data set is included</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>nasdaqdatalink</span><span class=o>.</span><span class=n>get_table</span><span class=p>(</span><span class=s1>&#39;QUOTEMEDIA/PRICES&#39;</span><span class=p>,</span> <span class=n>ticker</span> <span class=o>=</span> <span class=n>fund</span><span class=p>,</span> <span class=n>paginate</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Sort columns by date ascending</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;date&#39;</span><span class=p>,</span> <span class=n>ascending</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Rename date column</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;date&#39;</span><span class=p>:</span><span class=s1>&#39;Date&#39;</span><span class=p>},</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Set index to date column</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>set_index</span><span class=p>(</span><span class=s1>&#39;Date&#39;</span><span class=p>,</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Replace all split values of 1.0 with NaN</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Create a new data frame with split values only</span>
</span></span><span class=line><span class=cl>    <span class=n>df_splits</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;ticker&#39;</span><span class=p>,</span> <span class=s1>&#39;open&#39;</span><span class=p>,</span> <span class=s1>&#39;high&#39;</span><span class=p>,</span> <span class=s1>&#39;low&#39;</span><span class=p>,</span> <span class=s1>&#39;close&#39;</span><span class=p>,</span> <span class=s1>&#39;volume&#39;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                                   <span class=s1>&#39;dividend&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_open&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_high&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_low&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_close&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_volume&#39;</span><span class=p>})</span><span class=o>.</span><span class=n>dropna</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Create a new column for cumulative split</span>
</span></span><span class=line><span class=cl>    <span class=n>df_splits</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_splits</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>cumprod</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Drop original split column before combining dataframes</span>
</span></span><span class=line><span class=cl>    <span class=n>df_splits</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;split&#39;</span><span class=p>},</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Merge df and df_split dataframes</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>merge</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>df_splits</span><span class=p>,</span> <span class=n>on</span><span class=o>=</span><span class=s1>&#39;Date&#39;</span><span class=p>,</span> <span class=n>how</span><span class=o>=</span><span class=s1>&#39;outer&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Forward fill for all cumulative split values</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=n>method</span> <span class=o>=</span> <span class=s1>&#39;ffill&#39;</span><span class=p>,</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Replace all split and cumulative split values of NaN with 1.0 to have complete split values</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Calculate the non adjusted prices based on the splits only</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_open_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;open&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span> 
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_high_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;high&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>    
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_low_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;low&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>    
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_close_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;close&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_dividend_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;dividend&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Calculate the adjusted prices based on the splits</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Open&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_open_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;High&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_high_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Low&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_low_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Close&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_close_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_dividend_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend_Pct_Orig&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;dividend&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;close&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend_Pct_Adj&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Close&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Export data to excel</span>
</span></span><span class=line><span class=cl>    <span class=n>file</span> <span class=o>=</span> <span class=n>fund</span> <span class=o>+</span> <span class=s2>&#34;_NDL.xlsx&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>df_comp</span><span class=o>.</span><span class=n>to_excel</span><span class=p>(</span><span class=n>file</span><span class=p>,</span> <span class=n>sheet_name</span><span class=o>=</span><span class=s1>&#39;data&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Output confirmation</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;The last date of data for </span><span class=si>{</span><span class=n>fund</span><span class=si>}</span><span class=s2> is: &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>df_comp</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>:])</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;NDL data updater complete for </span><span class=si>{</span><span class=n>fund</span><span class=si>}</span><span class=s2> data&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;--------------------&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Let&rsquo;s break this down line by line.</p><h2 id=imports>Imports</h2><p>First, we need to import the required libraries:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Imports</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>nasdaqdatalink</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=ndl-api-key>NDL API Key</h2><p>To gain access to anything beyond the free tier, you will need to provide your access key:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Add API key for reference to allow access to unrestricted data</span>
</span></span><span class=line><span class=cl><span class=n>nasdaqdatalink</span><span class=o>.</span><span class=n>ApiConfig</span><span class=o>.</span><span class=n>api_key</span> <span class=o>=</span> <span class=s1>&#39;your_key&#39;</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=download-data-as-a-dataframe>Download data as a dataframe</h2><p>Moving on to the function definition, we have the command to pull data from NDL. There are two separate APIs - the <a class=link href=https://docs.data.nasdaq.com/docs/time-series target=_blank rel=noopener>time series</a> and the <a class=link href=https://docs.data.nasdaq.com/docs/tables-1 target=_blank rel=noopener>tables</a>. The syntax is different, and some data sets are only available as one or the other. We will use the tables API for this tutorial.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Command to pull data</span>
</span></span><span class=line><span class=cl><span class=c1># If start date and end date are not specified the entire data set is included</span>
</span></span><span class=line><span class=cl><span class=n>df</span> <span class=o>=</span> <span class=n>nasdaqdatalink</span><span class=o>.</span><span class=n>get_table</span><span class=p>(</span><span class=s1>&#39;QUOTEMEDIA/PRICES&#39;</span><span class=p>,</span> <span class=n>ticker</span> <span class=o>=</span> <span class=n>fund</span><span class=p>,</span> <span class=n>paginate</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>In the example above, the <code>fund</code> is an input parameter to the function.</p><p>The <code>'QUOTEMEDIA/PRICES'</code> is the data source that we are accessing.</p><p>There are many other arguments that we could pass in the above, including specifying columns, period start date, period end date, and others. Nasdaq as a few examples to get you started:</p><p><a class=link href=https://docs.data.nasdaq.com/docs/python-tables target=_blank rel=noopener>https://docs.data.nasdaq.com/docs/python-tables</a></p><p>Running:</p><pre><code>df.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/01_AAPL_data_first_10_rows.png width=1067 height=320 loading=lazy alt="AAPL Data - First 10 Rows" class=gallery-image data-flex-grow=333 data-flex-basis=800px></p><h2 id=sort-columns-by-date>Sort columns by date</h2><p>Next, we will sort the columns by date ascending. By default, the dataframe is created with the data sorted by descending date, and we want to change that:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Sort columns by date ascending</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>sort_values</span><span class=p>(</span><span class=s1>&#39;date&#39;</span><span class=p>,</span> <span class=n>ascending</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>The <code>inplace = True</code> argument specifies that the sort function should take effect on the existing dataframe.</p><p>Now, running:</p><pre><code>df.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/03_Sorted_by_date_ascending.png width=1039 height=321 loading=lazy alt="Data sorted by ascending date" class=gallery-image data-flex-grow=323 data-flex-basis=776px></p><h2 id=setting-the-date-as-the-index>Setting the date as the index</h2><p>Next, we will rename the <code>date</code> column from &lsquo;date&rsquo; to &lsquo;Date&rsquo;, and set the index to be the <code>Date</code> column:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Rename date column</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>rename</span><span class=p>(</span><span class=n>columns</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;date&#39;</span><span class=p>:</span><span class=s1>&#39;Date&#39;</span><span class=p>},</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=c1># Set index to date column</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=o>.</span><span class=n>set_index</span><span class=p>(</span><span class=s1>&#39;Date&#39;</span><span class=p>,</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Now, running:</p><pre><code>df.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/04_Date_as_the_index.png width=986 height=321 loading=lazy alt="Indexed by the ‘Date’ column" class=gallery-image data-flex-grow=307 data-flex-basis=737px></p><h2 id=calculating-splits>Calculating splits</h2><p>The next sections deal with the split column. So far we have only seen a split value of 1.0 in the data, but we&rsquo;ve only looked at the first 10 and last 10 rows. Are there any other values? Let&rsquo;s check by running:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>df_not_1_split</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span> <span class=o>!=</span> <span class=mf>1.0</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>And checking the first 10 rows:</p><pre><code>df_not_1_split.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/05_Actual_splits.png width=1059 height=192 loading=lazy alt="Split values" class=gallery-image data-flex-grow=551 data-flex-basis=1323px></p><p>So we now know that the stock did in fact split several times. Next, we will replace all of the <code>1.0</code> split values - because they are really meaningless - and then create a new dataframe to deal with the splits.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Replace all split values of 1.0 with NaN</span>
</span></span><span class=line><span class=cl><span class=n>df</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>This gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/06_Splits_replaced.png width=988 height=316 loading=lazy alt="Split values replaced with NaN" class=gallery-image data-flex-grow=312 data-flex-basis=750px></p><p>We will now create a dataframe with only the split values:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Create a new data frame with split values only</span>
</span></span><span class=line><span class=cl><span class=n>df_splits</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;ticker&#39;</span><span class=p>,</span> <span class=s1>&#39;open&#39;</span><span class=p>,</span> <span class=s1>&#39;high&#39;</span><span class=p>,</span> <span class=s1>&#39;low&#39;</span><span class=p>,</span> <span class=s1>&#39;close&#39;</span><span class=p>,</span> <span class=s1>&#39;volume&#39;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                               <span class=s1>&#39;dividend&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_open&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_high&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_low&#39;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                               <span class=s1>&#39;adj_close&#39;</span><span class=p>,</span> <span class=s1>&#39;adj_volume&#39;</span><span class=p>})</span><span class=o>.</span><span class=n>dropna</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Which gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/07_Dataframe_with_split_values_only.png width=156 height=195 loading=lazy alt="Dataframe with split values only" class=gallery-image data-flex-grow=80 data-flex-basis=192px></p><p>Creating a column for the cumulative split will provide an accurate perspective on the stock price. We can do that with the following:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Create a new column for cumulative split</span>
</span></span><span class=line><span class=cl><span class=n>df_splits</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_splits</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>cumprod</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>Which gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/08_Dataframe_with_cumulative_split_column.png width=234 height=195 loading=lazy alt="Dataframe with split and cumulative split values" class=gallery-image data-flex-grow=120 data-flex-basis=288px></p><p>We will then drop the original <code>split</code> column before combining the split data frame with the original data frame, as follows:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Drop original split column before combining dataframes</span>
</span></span><span class=line><span class=cl><span class=n>df_splits</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>columns</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;split&#39;</span><span class=p>},</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Which gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/09_Dataframe_with_only_cumulative_split_column.png width=194 height=193 loading=lazy alt="Dataframe with only cumulative split values" class=gallery-image data-flex-grow=100 data-flex-basis=241px></p><h2 id=combining-dataframes>Combining dataframes</h2><p>Now we will merge the <code>df_split</code> dataframe with the original <code>df</code> dataframe so that the cumulative split column is part of the original dataframe. We will call this data frame <code>df_comp</code>:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Merge df and df_split dataframes</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>merge</span><span class=p>(</span><span class=n>df</span><span class=p>,</span> <span class=n>df_splits</span><span class=p>,</span> <span class=n>on</span><span class=o>=</span><span class=s1>&#39;Date&#39;</span><span class=p>,</span> <span class=n>how</span><span class=o>=</span><span class=s1>&#39;outer&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>We are using the merge function of pandas, which includes arguments for the names of both dataframes to be merged, the column to match between the dataframes, and the parameter for the type of merge to be performed. The <code>outer</code> argument specifies that all rows from both dataframes will be included, and any missing values will be filled in with <code>NaN</code> if there is no matching data. This ensures that all data from both dataframes is retained.</p><p>Running:</p><pre><code>df_comp.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/10_Complete_dataframe_including_cumulative_split.png width=1060 height=317 loading=lazy alt="Complete dataframe incluidng the cumulative split values" class=gallery-image data-flex-grow=334 data-flex-basis=802px></p><h2 id=forward-filling-cumulative-split-values>Forward filling cumulative split values</h2><p>From here, we want to fill in the rest of the <code>split</code> and <code>Cum_Split</code> values. This is done using the forward fill function, which for all cells that have a value of <code>NaN</code> will fill in the previous valid value until another value is encountered. Here&rsquo;s the code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Forward fill for all cumulative split values</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=n>method</span> <span class=o>=</span> <span class=s1>&#39;ffill&#39;</span><span class=p>,</span> <span class=n>inplace</span> <span class=o>=</span> <span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Running:</p><pre><code>df_comp.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/11_Complete_dataframe_ffill_split_values_first_10_rows.png width=1029 height=344 loading=lazy alt="First 10 rows of complete dataframe with split values" class=gallery-image data-flex-grow=299 data-flex-basis=717px></p><p>At first glance, it doesn&rsquo;t look like anything changed. That&rsquo;s because there wasn&rsquo;t any ffill action taken on the initial values until pandas encountered a valid value to then forward fill. However, checking the last 10 rows:</p><pre><code>df_comp.tail(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/12_Complete_dataframe_ffill_split_values_last_10_rows.png width=1086 height=341 loading=lazy alt="Last 10 rows of complete dataframe with split values" class=gallery-image data-flex-grow=318 data-flex-basis=764px></p><p>Which is the result that we were expecting. But, what about the first rows from 12/12/1980 to 6/15/1987? We can fill those <code>split</code> and <code>Cum_Split</code> values with the following code:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Replace all split and cumulative split values of NaN with 1.0 to have complete split values</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>Now, checking the first 10 rows:</p><pre><code>df_comp.head(10)
</code></pre><p>Gives us:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/13_Complete_dataframe_ffill_split_values_first_10_rows.png width=1068 height=317 loading=lazy alt="First 10 rows of complete dataframe with split values" class=gallery-image data-flex-grow=336 data-flex-basis=808px></p><p>With this data, we now know for every day in the data set the following pieces of information:</p><ol><li>If the stock split on that day</li><li>What the total split ratio is up to and including that day</li></ol><h2 id=calculating-adjusted-and-non-adjusted-prices>Calculating adjusted and non-adjusted prices</h2><p>From here, we can complete our dataset by calculating the adjusted and non-adjusted prices using the cumulative split ratios from above:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Calculate the non adjusted prices based on the splits only</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_open_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;open&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span> 
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_high_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;high&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>    
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_low_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;low&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>    
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_close_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;close&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_dividend_split_only&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;dividend&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Calculate the adjusted prices based on the splits</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Open&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_open_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;High&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_high_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Low&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_low_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Close&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_close_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;non_adj_dividend_split_only&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Cum_Split&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend_Pct_Orig&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;dividend&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;close&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend_Pct_Adj&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Dividend&#39;</span><span class=p>]</span> <span class=o>/</span> <span class=n>df_comp</span><span class=p>[</span><span class=s1>&#39;Close&#39;</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>Included above is the adjusted dividends values. For any time series analysis, not only are the adjusted prices needed, but so are the adusted dividends. Remember, we already have the adjusted total return prices - those come directly from NDL.</p><h2 id=export-data>Export data</h2><p>Next, we want to export the data to an excel file, for easy viewing and reference later:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Export data to excel</span>
</span></span><span class=line><span class=cl><span class=n>file</span> <span class=o>=</span> <span class=n>fund</span> <span class=o>+</span> <span class=s2>&#34;_NDL.xlsx&#34;</span>
</span></span><span class=line><span class=cl><span class=n>df_comp</span><span class=o>.</span><span class=n>to_excel</span><span class=p>(</span><span class=n>file</span><span class=p>,</span> <span class=n>sheet_name</span><span class=o>=</span><span class=s1>&#39;data&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>And verify the output is as expected:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/14_Excel_export.png width=3491 height=220 loading=lazy alt="Excel export" class=gallery-image data-flex-grow=1586 data-flex-basis=3808px></p><h2 id=output-confirmation>Output confirmation</h2><p>Finally, we want to print a confirmation that the process succeeded along withe last date we have for data:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Output confirmation</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;The last date of data for </span><span class=si>{</span><span class=n>fund</span><span class=si>}</span><span class=s2> is: &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>df_comp</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>:])</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;NDL data updater complete for </span><span class=si>{</span><span class=n>fund</span><span class=si>}</span><span class=s2> data&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;--------------------&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>And confirming the output:</p><p><img src=/2023/12/24/nasdaq-data-link-tables-api-data-retrieval/15_Output_confirmation.png width=643 height=470 loading=lazy alt="Output confirmation" class=gallery-image data-flex-grow=136 data-flex-basis=328px></p><h2 id=references>References</h2><p><a class=link href=https://docs.data.nasdaq.com/docs target=_blank rel=noopener>https://docs.data.nasdaq.com/docs</a></br><a class=link href=https://docs.data.nasdaq.com/docs/tables-1 target=_blank rel=noopener>https://docs.data.nasdaq.com/docs/tables-1</a></br><a class=link href=https://docs.data.nasdaq.com/docs/time-series target=_blank rel=noopener>https://docs.data.nasdaq.com/docs/time-series</a></br><a class=link href=https://docs.data.nasdaq.com/docs/python target=_blank rel=noopener>https://docs.data.nasdaq.com/docs/python</a></p></section><footer class=article-footer><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on December 26, 2023</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=[".main-article",".widget--toc"];e.forEach(e=>{const t=document.querySelector(e);t&&renderMathInElement(t,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/2025/02/02/reusable-extensible-python-functions-financial-data-analysis/><div class=article-image><img src=/2025/02/02/reusable-extensible-python-functions-financial-data-analysis/cover.2a062c1ce4dbbd3eb420903d6e11fb5a.jpg width=1920 height=800 loading=lazy alt="Featured image of post Reusable And Extensible Python Functions For Financial Data Analysis" data-key=reusable-extensible-python-functions-financial-data-analysis data-hash="md5-KgYsHOTbvT60IJA9bhH7Wg=="></div><div class=article-details><h2 class=article-title>Reusable And Extensible Python Functions For Financial Data Analysis</h2></div></a></article><article class=has-image><a href=/2025/11/29/asset-class-performance-fed-policy-cycles/><div class=article-image><img src=/2025/11/29/asset-class-performance-fed-policy-cycles/asset-class-performance-fed-policy-cycles.80d1e3dba00bcbca2f291ef95f0b4e73.png width=1536 height=1024 loading=lazy alt="Featured image of post Performance Of Various Asset Classes During Fed Policy Cycles" data-key=asset-class-performance-fed-policy-cycles data-hash="md5-gNHj26ALy8ovKR75XwtOcw=="></div><div class=article-details><h2 class=article-title>Performance Of Various Asset Classes During Fed Policy Cycles</h2></div></a></article><article class=has-image><a href=/2025/08/10/data-pipelining-with-polygon/><div class=article-image><img src=/2025/08/10/data-pipelining-with-polygon/data-pipelining-with-polygon_original2.282db02a9a1d34f8f9e56ff26e35e2e3.png width=1536 height=1024 loading=lazy alt="Featured image of post Data Pipelining With Polygon" data-key=data-pipelining-with-polygon data-hash="md5-KC2wKpodNPj55W/ybjXi4w=="></div><div class=article-details><h2 class=article-title>Data Pipelining With Polygon</h2></div></a></article><article class=has-image><a href=/2025/07/06/data-pipelining-with-coinbase/><div class=article-image><img src=/2025/07/06/data-pipelining-with-coinbase/data-pipelining-with-coinbase.23405301a063b1b5afccbd3035f271ce.png width=1891 height=788 loading=lazy alt="Featured image of post Data Pipelining With Coinbase" data-key=data-pipelining-with-coinbase data-hash="md5-I0BTAaBjsbWvzL0wNfJxzg=="></div><div class=article-details><h2 class=article-title>Data Pipelining With Coinbase</h2></div></a></article><article class=has-image><a href=/2025/03/03/investigating-a-vix-trading-signal-part-3-trading/><div class=article-image><img src=/2025/03/03/investigating-a-vix-trading-signal-part-3-trading/cover.6c26bbaa157bd04e55552d08c0af8235.jpg width=1920 height=800 loading=lazy alt="Featured image of post Investigating A VIX Trading Signal, Part 3: Trading" data-key=investigating-a-vix-trading-signal-part-3-trading data-hash="md5-bCa7qhV70E5VVS0IwK+CNQ=="></div><div class=article-details><h2 class=article-title>Investigating A VIX Trading Signal, Part 3: Trading</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=jaredszajkowski/jaredszajkowski.github.io data-repo-id=R_kgDOKZLn5w data-category=Announcements data-category-id=DIC_kwDOKZLn584CaJwO data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=en data-loading crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark")}})()</script><footer class=site-footer><section class=copyright>&copy;
2023 -
2025 Jared Szajkowski, P.E., PMP</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.33.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>